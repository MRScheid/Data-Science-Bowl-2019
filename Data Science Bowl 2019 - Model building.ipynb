{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\micha\\Desktop\\Kaggle - Data Science Bowl 2019'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')#, index_col='timestamp', parse_dates=True) #,usecols=keep_cols)\n",
    "train_labels = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 778.73 Mb (18.2% reduction)\n",
      "Mem. usage decreased to  0.49 Mb (48.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "train_labels = reduce_mem_usage(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 11341042 entries, (0001e90f, MAGMAPEAK, 2019-09-06T17:54:17.519Z) to (fffc0583, TREETOPCITY, 2019-10-10T15:15:12.483Z)\n",
      "Data columns (total 14 columns):\n",
      "event_id          object\n",
      "game_session      object\n",
      "event_data        object\n",
      "event_count       int16\n",
      "event_code        int16\n",
      "game_time         int32\n",
      "title_x           object\n",
      "type              object\n",
      "title_y           object\n",
      "num_correct       float64\n",
      "num_incorrect     float64\n",
      "accuracy          float16\n",
      "accuracy_group    float64\n",
      "assessment_id     float64\n",
      "dtypes: float16(1), float64(4), int16(2), int32(1), object(6)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "train_labels['assessment_id'] = range(1,len(train_labels)+1)\n",
    "\n",
    "# Merge train_labels info with event data info to look at accuracy groups with respect to\n",
    "# different event info\n",
    "train_order = pd.merge_ordered(left = train, right = train_labels, \n",
    "                 on = ['installation_id','game_session'], how='left')\n",
    "train_order.sort_index()\n",
    "\n",
    "\n",
    "### Fill in missing accuracy group values for all events and\n",
    "### set index to variables that dataframe will be grouped by\n",
    "# First set index and sort chronologically within an \n",
    "#   [installation_id, world] pair with timestamp in index\n",
    "train_time = train_order.set_index(['installation_id','world','timestamp'])\n",
    "del train_order\n",
    "\n",
    "train_time = train_time.sort_index()\n",
    "\n",
    "# Backfill NaN values of events around assessments, bounded by installation_id and world \n",
    "train_time = train_time.groupby(level=['installation_id','world']).bfill()\n",
    "\n",
    "train_time.info()\n",
    "\n",
    "# # 'Clip' type activties don't have a gametime, so we need to fill in a time.  Assume about 2min / clip.\n",
    "train_time_clips = train_time[train_time['type'] == 'Clip'].replace(0,120000)['game_time']\n",
    "train_time.loc[train_time['type'] == 'Clip','game_time'] = train_time_clips \n",
    "\n",
    "# Then fill the rest of the events with 0 for those events \n",
    "# not associated with installation_ids or game_sessions where an assessment took place.  \n",
    "train_time = train_time.fillna(0)\n",
    "\n",
    "# Add accuracy_group and type to index so you can do a multi-level sort\n",
    "train_time = train_time.set_index(['game_session','accuracy_group','assessment_id','type'],append=True)\n",
    "\n",
    "# Auto-dispatch the sum aggregation on multi-level group using the groupby method\n",
    "# Essentially sum the amount of time for each type of gameplay for a particular installation_id ->\n",
    "# world -> accuracy_group -> type of event to get an estimate of time spent in \n",
    "# each type of activity\n",
    "train_time_agg = train_time.groupby( \\\n",
    "                 level=['installation_id','world','assessment_id','game_session']) \\\n",
    "                 .last()['game_time']\n",
    "\n",
    "train_time_agg = train_time['game_time'].groupby(level=['installation_id','world',\\\n",
    "                                                        'assessment_id','type','accuracy_group'])\\\n",
    "                                                        .agg(game_time='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now unstack the type column to get counts for each type of activity within each \n",
    "# [installation_id, world] pair\n",
    "train_time = train_time_agg.unstack('type')\n",
    "\n",
    "# Fill all those gameplay times that are empty with zeros so that the next step,\n",
    "# the cumulative sum below, executes correctly. \n",
    "train_time = train_time.fillna(0)\n",
    "\n",
    "# Calculate the cumulative sum of game time at assessment time in each type of gameplay for each \n",
    "# [installation_id world] pair\n",
    "train_time = train_time['game_time'].groupby(level=['installation_id','world'])\\\n",
    "                                        .transform(pd.DataFrame.cumsum)\n",
    "\n",
    "train_time = train_time.unstack('world')\n",
    "\n",
    "del train_time_agg\n",
    "\n",
    "# Fill all [installation_id, world] rows that are missing an activity count with zeros\n",
    "train_time = train_time.fillna(0)\n",
    "\n",
    "# Now move the accuracy group out of the index to look at \n",
    "# correlation with type of activity counts\n",
    "# train_time.reset_index(level=3, inplace=True)\n",
    "\n",
    "# If unstacking world\n",
    "train_time.reset_index(level=2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3946: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to build models with the gameplay time features\n",
    "\n",
    "# Create arrays for the features and the response variable\n",
    "y = train_time['accuracy_group'].values\n",
    "X = train_time.drop(['accuracy_group','Assessment'], axis=1).values\n",
    "\n",
    "# del train_time\n",
    "\n",
    "# Create a k-NN classifier with 4 neighbors, one for each accuracy_group\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7522407170294494\n",
      "[0.61594414 0.61908919 0.61574276 0.63285797 0.62281723]\n",
      "Average 5-Fold CV Score: 0.6212902584334759\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "print(knn.score(X, y))\n",
    "\n",
    "y_pred = knn.predict(X)\n",
    "\n",
    "cv_scores = cross_val_score(knn, X, y, cv = 5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print(cv_scores)\n",
    "\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its important to use binary mode \n",
    "knnPickle = open('knn_World2_pickle_file', 'wb') \n",
    "\n",
    "# source, destination \n",
    "pickle.dump(knn, knnPickle)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
